name: Player Scores Data Pipeline

on:
  schedule:
    - cron: '0 4 * * TUE'

jobs:
  data-pipeline:

    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}

    steps:
    - run: |
        echo "${{ github.event.head_commit.message }}"
    - uses: actions/checkout@v2
    - uses: conda-incubator/setup-miniconda@v2
      with:
        environment-file: environment.yml
        activate-environment: player-scores
    - name: Run pipeline
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        python -m ipykernel install --user --name player-scores
        dvc repro
    - name: Update kaggle dataset
      env:
        KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
        KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
      run: |
        kaggle datasets version -p data/prep -m 'Automatic update from github actions' -d
